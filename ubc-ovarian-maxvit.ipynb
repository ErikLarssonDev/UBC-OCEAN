{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Environment setup","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom typing import Dict, List\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import balanced_accuracy_score\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom pathlib import Path\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(pow(2,60))\nprint(f\"torch version {torch.__version__}\") \nprint(f'Torchvision version {torchvision.__version__}')","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.449533Z","iopub.execute_input":"2023-10-27T10:13:53.449885Z","iopub.status.idle":"2023-10-27T10:13:53.461612Z","shell.execute_reply.started":"2023-10-27T10:13:53.449856Z","shell.execute_reply":"2023-10-27T10:13:53.460734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    \"seed\": 42,\n    \"img_size\": 224,\n    \"model_name\": \"maxvit\",\n    \"num_classes\": 5,\n    \"valid_batch_size\": 64,\n    \"test_batch_size\": 1,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    \"train\": False, # To train and save the model. Should be False when submitting\n    \"split_ratio\": 0.2,\n    \"num_workers\": os.cpu_count(),\n    \"epochs\": 8,\n    \"sandbox\": False, # True when finding optimal hyperparameters. Should be False when submitting.\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.463104Z","iopub.execute_input":"2023-10-27T10:13:53.463356Z","iopub.status.idle":"2023-10-27T10:13:53.478118Z","shell.execute_reply.started":"2023-10-27T10:13:53.463334Z","shell.execute_reply":"2023-10-27T10:13:53.477190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.479859Z","iopub.execute_input":"2023-10-27T10:13:53.480198Z","iopub.status.idle":"2023-10-27T10:13:53.489917Z","shell.execute_reply.started":"2023-10-27T10:13:53.480166Z","shell.execute_reply":"2023-10-27T10:13:53.489042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input/UBC-OCEAN'\nTEST_DIR = '/kaggle/input/UBC-OCEAN/test_thumbnails'\nALT_TEST_DIR = '/kaggle/input/UBC-OCEAN/test_images'\nTRAIN_DIR = '/kaggle/input/UBC-OCEAN/train_thumbnails'\nALT_TRAIN_DIR = '/kaggle/input/UBC-OCEAN/train_images'","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.490864Z","iopub.execute_input":"2023-10-27T10:13:53.491123Z","iopub.status.idle":"2023-10-27T10:13:53.505956Z","shell.execute_reply.started":"2023-10-27T10:13:53.491101Z","shell.execute_reply":"2023-10-27T10:13:53.505258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data processing","metadata":{}},{"cell_type":"code","source":"def get_test_file_path(image_id):\n    if os.path.exists(f\"{TEST_DIR}/{image_id}_thumbnail.png\"):\n        return f\"{TEST_DIR}/{image_id}_thumbnail.png\"\n    else: \n        return f\"{ALT_TEST_DIR}/{image_id}.png\"","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.507911Z","iopub.execute_input":"2023-10-27T10:13:53.508248Z","iopub.status.idle":"2023-10-27T10:13:53.516946Z","shell.execute_reply.started":"2023-10-27T10:13:53.508215Z","shell.execute_reply":"2023-10-27T10:13:53.516045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf['file_path'] = df['image_id'].apply(get_test_file_path)\ndf['label'] = 0 # dummy\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.517950Z","iopub.execute_input":"2023-10-27T10:13:53.518232Z","iopub.status.idle":"2023-10-27T10:13:53.537599Z","shell.execute_reply.started":"2023-10-27T10:13:53.518209Z","shell.execute_reply":"2023-10-27T10:13:53.536752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UBCDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        print(df['label'].values)\n        self.labels = df['label'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        label = self.labels[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return torch.tensor(img), torch.tensor(label, dtype=torch.long)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.538534Z","iopub.execute_input":"2023-10-27T10:13:53.538793Z","iopub.status.idle":"2023-10-27T10:13:53.546119Z","shell.execute_reply.started":"2023-10-27T10:13:53.538769Z","shell.execute_reply":"2023-10-27T10:13:53.545045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.547305Z","iopub.execute_input":"2023-10-27T10:13:53.547647Z","iopub.status.idle":"2023-10-27T10:13:53.557775Z","shell.execute_reply.started":"2023-10-27T10:13:53.547614Z","shell.execute_reply":"2023-10-27T10:13:53.557034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    if os.path.exists(f\"{TRAIN_DIR}/{image_id}_thumbnail.png\"):\n        return f\"{TRAIN_DIR}/{image_id}_thumbnail.png\"\n    else:\n        return f\"{ALT_TRAIN_DIR}/{image_id}.png\"","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.560261Z","iopub.execute_input":"2023-10-27T10:13:53.560878Z","iopub.status.idle":"2023-10-27T10:13:53.571128Z","shell.execute_reply.started":"2023-10-27T10:13:53.560842Z","shell.execute_reply":"2023-10-27T10:13:53.570237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf = pd.read_csv('/kaggle/input/UBC-OCEAN/train.csv')\n\ntraindf['label'][traindf['label']==\"HGSC\"] = 0\ntraindf['label'][traindf['label']==\"EC\"] = 1\ntraindf['label'][traindf['label']==\"CC\"] = 2\ntraindf['label'][traindf['label']==\"LGSC\"] = 3\ntraindf['label'][traindf['label']==\"MC\"] = 4\ntraindf['file_path'] = traindf['image_id'].apply(get_train_file_path)\ntraindf","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.572181Z","iopub.execute_input":"2023-10-27T10:13:53.572438Z","iopub.status.idle":"2023-10-27T10:13:53.611105Z","shell.execute_reply.started":"2023-10-27T10:13:53.572415Z","shell.execute_reply":"2023-10-27T10:13:53.610458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing data transforms with random training images","metadata":{}},{"cell_type":"code","source":"def visualize_transformed_image(dataframe, transform):\n    # Select a random row from the DataFrame\n    random_row = dataframe.sample(n=1).iloc[0]\n\n    # Get the image file path from the selected row\n    file_path = random_row['file_path']\n    print(random_row['is_tma'])\n    print(file_path)\n    # Load the original image\n    original_image = cv2.imread(file_path)\n\n    # Apply the transform to the original image\n    transformed_image = transform(image=original_image)[\"image\"]\n\n    # Visualize the original and transformed images\n    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n\n    axes[0].set_title('Original Image')\n    axes[0].imshow(original_image)\n    axes[0].axis('off')\n\n    axes[1].set_title('Transformed Image')\n    axes[1].imshow(transformed_image.permute(1, 2, 0))\n    axes[1].axis('off')\n\n    plt.show()\n\n# Visualize a random image from the DataFrame with the transform applied\nif CONFIG[\"sandbox\"]:\n    visualize_transformed_image(traindf, data_transforms[\"valid\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.612119Z","iopub.execute_input":"2023-10-27T10:13:53.612845Z","iopub.status.idle":"2023-10-27T10:13:53.620920Z","shell.execute_reply.started":"2023-10-27T10:13:53.612819Z","shell.execute_reply":"2023-10-27T10:13:53.619272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the training data frame for training","metadata":{}},{"cell_type":"code","source":"train_dataset = UBCDataset(traindf, transforms=data_transforms[\"valid\"]) # TODO: Add training transforms\ntrain_dataloader = DataLoader(train_dataset, batch_size=CONFIG['valid_batch_size'], \n                          num_workers=CONFIG[\"num_workers\"], shuffle=True, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.622504Z","iopub.execute_input":"2023-10-27T10:13:53.622864Z","iopub.status.idle":"2023-10-27T10:13:53.638549Z","shell.execute_reply.started":"2023-10-27T10:13:53.622831Z","shell.execute_reply":"2023-10-27T10:13:53.637192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and validation split from the training set","metadata":{}},{"cell_type":"code","source":"# Split the data into training and validation sets\nif CONFIG[\"sandbox\"]:\n    train_data, val_data = train_test_split(traindf, test_size=CONFIG[\"split_ratio\"], random_state=CONFIG[\"seed\"])\n\n    train_dataset = UBCDataset(train_data, transforms=data_transforms[\"valid\"]) # TODO: Add training transforms\n    train_dataloader = DataLoader(train_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=CONFIG[\"num_workers\"], shuffle=True, pin_memory=True)\n\n    val_dataset = UBCDataset(val_data, transforms=data_transforms[\"valid\"]) \n    val_dataloader = DataLoader(val_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=CONFIG[\"num_workers\"], shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.640613Z","iopub.execute_input":"2023-10-27T10:13:53.641053Z","iopub.status.idle":"2023-10-27T10:13:53.656090Z","shell.execute_reply.started":"2023-10-27T10:13:53.641016Z","shell.execute_reply":"2023-10-27T10:13:53.654783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and save model","metadata":{}},{"cell_type":"markdown","source":"## Save model","metadata":{}},{"cell_type":"code","source":"def save_model(model: torch.nn.Module,\n               target_dir: str,\n               model_name: str):\n    \"\"\"Saves a PyTorch model to a target directory.\n    \n    Args:\n        model: A target PyTorch model to save.\n        target_dir: A directory for saving the model to.\n        model_name: A filename for the saved model. Should include either \".pth\" or \".pt\" as the file extension.\n        \n    Example usage:\n        save_model(model=model_0,\n        targer_dir=\"models\", \n        model_name=\"model_1\")\n    \"\"\"\n\n    # Create target directory\n    target_dir_path = Path(target_dir)\n    target_dir_path.mkdir(parents=True,\n                          exist_ok=True)\n\n    # Create model save path\n    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"),  \"model_name should end with '.pt' or '.pth'\"\n    model_save_path = target_dir_path / model_name\n\n    # Save the model state_dict()\n    print(f\"[INFO] Saving model to : {model_save_path}\")\n    torch.save(obj=model,\n               f=model_save_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.656953Z","iopub.execute_input":"2023-10-27T10:13:53.657299Z","iopub.status.idle":"2023-10-27T10:13:53.670392Z","shell.execute_reply.started":"2023-10-27T10:13:53.657269Z","shell.execute_reply":"2023-10-27T10:13:53.669331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing a pretrained model\nThis is done online before we turn off the internet access. ","metadata":{}},{"cell_type":"code","source":"if CONFIG[\"train\"] or CONFIG[\"sandbox\"]:\n    # 1. Get pretrained weights for the model\n    pretrained_weights = torchvision.models.MaxVit_T_Weights.DEFAULT\n    \n    # 2. Setup a ViT model instance with pretrained weights\n    pretrained_model = torchvision.models.maxvit_t(weights=pretrained_weights).to(CONFIG[\"device\"])\n\n    # 3. Freeze the base parameters\n    for parameter in pretrained_model.parameters():\n        parameter.requires_grad = False\n        parameter.to(CONFIG[\"device\"])\n\n    # 4. Change the classifier head\n    set_seed() \n    classifier = list(pretrained_model.children())[-1][:-1]\n    head = nn.Sequential(\n            nn.Linear(in_features=512, out_features = 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(in_features=256, out_features=64),\n            nn.ReLU(),\n            nn.Dropout(0.15),\n            nn.Linear(in_features=64, out_features = CONFIG[\"num_classes\"])\n    )\n    classifier = nn.Sequential(*classifier, *head)\n    print(classifier)\n    pretrained_model.classifier = classifier.to(CONFIG[\"device\"])\n\n    save_model(pretrained_model, # Needs to be saved as a dataset so that it works offline\n             \"/kaggle/working/\",\n             f\"{CONFIG['model_name']}-pretrained.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.671473Z","iopub.execute_input":"2023-10-27T10:13:53.671729Z","iopub.status.idle":"2023-10-27T10:13:53.685473Z","shell.execute_reply.started":"2023-10-27T10:13:53.671706Z","shell.execute_reply":"2023-10-27T10:13:53.684635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"\"\"\"\nContains functions for training and testing a PyTorch model.\n\"\"\"\nimport torch\n\nfrom tqdm.auto import tqdm\nfrom typing import Dict, List, Tuple\n\ndef train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device) -> Tuple[float, float]:\n    \"\"\"Trains a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to training mode and then\n    runs through all of the required training steps (forward\n    pass, loss calculation, optimizer step).\n\n    Args:\n    model: A PyTorch model to be trained.\n    dataloader: A DataLoader instance for the model to be trained on.\n    loss_fn: A PyTorch loss function to minimize.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of training loss and training accuracy metrics.\n    In the form (train_loss, train_accuracy). For example:\n\n    (0.1112, 0.8743)\n    \"\"\"\n    # Put model in train mode\n    model.train()\n\n    # Setup train loss and train accuracy values\n    train_loss, train_acc = 0, 0\n\n    # Loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. Calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item() \n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n        # Calculate and accumulate accuracy metric across all batches\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n\n    # Adjust metrics to get average loss and accuracy per batch \n    train_loss = train_loss / len(dataloader)\n    train_acc = train_acc / len(dataloader)\n    return train_loss, train_acc\n\ndef test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader, \n              loss_fn: torch.nn.Module,\n              device: torch.device) -> Tuple[float, float]:\n    \"\"\"Tests a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to \"eval\" mode and then performs\n    a forward pass on a testing dataset.\n\n    Args:\n    model: A PyTorch model to be tested.\n    dataloader: A DataLoader instance for the model to be tested on.\n    loss_fn: A PyTorch loss function to calculate loss on the test data.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of testing loss and testing accuracy metrics.\n    In the form (test_loss, test_accuracy). For example:\n\n    (0.0223, 0.8985)\n    \"\"\"\n    # Put model in eval mode\n    model.eval() \n\n    # Setup test loss and test accuracy values\n    test_loss, test_acc, balanced_acc = 0, 0, 0\n    pred_labels = []\n    true_labels = []\n    # Turn on inference context manager\n    with torch.inference_mode():\n        # Loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # Send data to target device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred_logits = model(X)\n\n            # 2. Calculate and accumulate loss\n            loss = loss_fn(test_pred_logits, y)\n            test_loss += loss.item()\n\n            # Calculate and accumulate accuracy\n            test_pred_labels = test_pred_logits.argmax(dim=1)\n            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n            pred_labels = pred_labels + test_pred_labels.cpu().tolist()\n            true_labels = true_labels + y.cpu().tolist()\n\n    # Adjust metrics to get average loss and accuracy per batch \n    test_loss = test_loss / len(dataloader)\n    test_acc = test_acc / len(dataloader)\n    balanced_acc = balanced_accuracy_score(true_labels, pred_labels)\n    return test_loss, test_acc, balanced_acc\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device) -> Dict[str, List]:\n    \"\"\"Trains and tests a PyTorch model.\n\n    Passes a target PyTorch models through train_step() and test_step()\n    functions for a number of epochs, training and testing the model\n    in the same epoch loop.\n\n    Calculates, prints and stores evaluation metrics throughout.\n\n    Args:\n    model: A PyTorch model to be trained and tested.\n    train_dataloader: A DataLoader instance for the model to be trained on.\n    test_dataloader: A DataLoader instance for the model to be tested on.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n    epochs: An integer indicating how many epochs to train for.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A dictionary of training and testing loss as well as training and\n    testing accuracy metrics. Each metric has a value in a list for \n    each epoch.\n    In the form: {train_loss: [...],\n                  train_acc: [...],\n                  test_loss: [...],\n                  test_acc: [...]} \n    For example if training for epochs=2: \n                 {train_loss: [2.0616, 1.0537],\n                  train_acc: [0.3945, 0.3945],\n                  test_loss: [1.2641, 1.5706],\n                  test_acc: [0.3400, 0.2973]} \n    \"\"\"\n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n                \"train_acc\": [],\n                \"test_loss\": [],\n                \"test_acc\": [],\n                \"balanced_acc\": [],\n                }\n\n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                          dataloader=train_dataloader,\n                                          loss_fn=loss_fn,\n                                          optimizer=optimizer,\n                                          device=device)\n        test_loss, test_acc, balanced_acc = test_step(model=model,\n          dataloader=test_dataloader,\n          loss_fn=loss_fn,\n          device=device)\n\n        # Print out what's happening\n        print(\n                f\"Epoch: {epoch+1} | \"\n                f\"train_loss: {train_loss:.4f} | \"\n                f\"train_acc: {train_acc:.4f} | \"\n                f\"test_loss: {test_loss:.4f} | \"\n                f\"test_acc: {test_acc:.4f} | \"\n                f\"balanced_acc: {balanced_acc:.4f}\"\n        )\n\n        # Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        results[\"balanced_acc\"].append(balanced_acc)\n\n    # Return the filled results at the end of the epochs\n    return results","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.690210Z","iopub.execute_input":"2023-10-27T10:13:53.690511Z","iopub.status.idle":"2023-10-27T10:13:53.716962Z","shell.execute_reply.started":"2023-10-27T10:13:53.690486Z","shell.execute_reply":"2023-10-27T10:13:53.715948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create optimizer and loss function\ndef train_model(train_dl, test_dl, model_name, store_model=True):\n    optimizer = torch.optim.Adam(params=pretrained_model.parameters(),\n                                 lr=1e-3)\n    loss_fn = torch.nn.CrossEntropyLoss()\n    \n    if test_dl is None:\n        test_dl = train_dl\n    # Train the classifier head of the pretrained ViT feature extractor model\n    set_seed()\n    results = train(model=pretrained_model,\n                   train_dataloader=train_dl,\n                   test_dataloader=test_dl,\n                   optimizer=optimizer,\n                   loss_fn=loss_fn,\n                   epochs=CONFIG[\"epochs\"],\n                   device=CONFIG[\"device\"])\n    if store_model:\n        save_model(pretrained_model, # Needs to be saved as a dataset so that it works offline\n                 \"/kaggle/working/\",\n                 model_name)\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.718169Z","iopub.execute_input":"2023-10-27T10:13:53.718459Z","iopub.status.idle":"2023-10-27T10:13:53.732635Z","shell.execute_reply.started":"2023-10-27T10:13:53.718435Z","shell.execute_reply":"2023-10-27T10:13:53.731675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG[\"train\"]:\n    results = train_model(train_dl=train_dataloader, test_dl=train_dataloader, model_name=f\"{CONFIG['model_name']}.pth\")\nelif CONFIG[\"sandbox\"]:\n    results = train_model(train_dl=train_dataloader, test_dl=val_dataloader, model_name=f\"{CONFIG['model_name']}.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.733858Z","iopub.execute_input":"2023-10-27T10:13:53.734130Z","iopub.status.idle":"2023-10-27T10:13:53.747298Z","shell.execute_reply.started":"2023-10-27T10:13:53.734107Z","shell.execute_reply":"2023-10-27T10:13:53.746378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_curves(results: Dict[str, List[float]]):\n    \"\"\"Plots training curves of a results dictionary.\n\n    Args:\n        results (dict): dictionary containing list of values, e.g.\n            {\"train_loss\": [...],\n             \"train_acc\": [...],\n             \"test_loss\": [...],\n             \"test_acc\": [...]}\n    \"\"\"\n\n    # Get the loss values of the results dictionary (training and test)\n    loss = results['train_loss']\n    test_loss = results['test_loss']\n\n    # Get the accuracy values of the results dictionary (training and test)\n    accuracy = results['train_acc']\n    test_accuracy = results['test_acc']\n\n    # Figure out how many epochs there were\n    epochs = range(len(results['train_loss']))\n\n    # Setup a plot\n    plt.figure(figsize=(15, 7))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss, label='train_loss')\n    plt.plot(epochs, test_loss, label='test_loss')\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, accuracy, label='train_accuracy')\n    plt.plot(epochs, test_accuracy, label='test_accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()\n    \n    # Plot accuracy\n    plt.subplot(1, 1, 1)\n    plt.plot(epochs, results[\"balanced_acc\"], label='balanced_acc')\n    plt.title('Balanced Accuracy for validation data')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.748687Z","iopub.execute_input":"2023-10-27T10:13:53.748974Z","iopub.status.idle":"2023-10-27T10:13:53.758576Z","shell.execute_reply.started":"2023-10-27T10:13:53.748951Z","shell.execute_reply":"2023-10-27T10:13:53.757647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss curves\nif CONFIG[\"train\"] or CONFIG[\"sandbox\"]:\n    plot_loss_curves(results) ","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.759558Z","iopub.execute_input":"2023-10-27T10:13:53.760115Z","iopub.status.idle":"2023-10-27T10:13:53.772449Z","shell.execute_reply.started":"2023-10-27T10:13:53.760090Z","shell.execute_reply":"2023-10-27T10:13:53.771562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the model","metadata":{}},{"cell_type":"code","source":"if CONFIG[\"train\"] or CONFIG[\"sandbox\"]:\n    model = torch.load(f\"/kaggle/working/{CONFIG['model_name']}.pth\")\nelse:\n    model = torch.load(f\"/kaggle/input/{CONFIG['model_name']}-trained/{CONFIG['model_name']}.pth\") # Needs to be loaded from the input folder so that it works offline","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:53.773633Z","iopub.execute_input":"2023-10-27T10:13:53.773927Z","iopub.status.idle":"2023-10-27T10:13:54.424729Z","shell.execute_reply.started":"2023-10-27T10:13:53.773902Z","shell.execute_reply":"2023-10-27T10:13:54.423700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing on the validation data","metadata":{}},{"cell_type":"code","source":"# Confusion matrix","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.426277Z","iopub.execute_input":"2023-10-27T10:13:54.426573Z","iopub.status.idle":"2023-10-27T10:13:54.430643Z","shell.execute_reply.started":"2023-10-27T10:13:54.426548Z","shell.execute_reply":"2023-10-27T10:13:54.429731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot images and make predictions for manual testing\ndef show_images_from_dataframe(dataframe, num_images):\n    # Select 'num_images' random rows from the DataFrame\n    selected_rows = dataframe.sample(num_images)\n    \n    for _, row in selected_rows.iterrows():\n        file_path = row['file_path']\n        image = cv2.imread(file_path)\n        \n        plt.figure(figsize=(10, 10))\n        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        plt.title(f\"Image ID: {row['image_id']}\")\n        plt.axis('off')\n        plt.show()\n    return selected_rows\n\nif CONFIG[\"sandbox\"]:        \n    selected_rows = show_images_from_dataframe(val_data, 5)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.431657Z","iopub.execute_input":"2023-10-27T10:13:54.431943Z","iopub.status.idle":"2023-10-27T10:13:54.442586Z","shell.execute_reply.started":"2023-10-27T10:13:54.431910Z","shell.execute_reply":"2023-10-27T10:13:54.441636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TODO: Check this later\ndef predict_and_visualize_images_with_labels(selected_rows, model):\n    model.eval()\n\n    for _, row in selected_rows.iterrows():\n        file_path = row['file_path']\n        image = cv2.imread(file_path)\n\n        # Preprocess the image for the model\n        transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n        input_image = transform(image).unsqueeze(0)\n\n        # Perform inference\n        with torch.no_grad():\n            output = model(input_image)\n\n        # Get the predicted class label\n        predicted_class = torch.argmax(output).item()\n\n        plt.figure(figsize=(8, 8))\n        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        plt.title(f\"Image ID: {row['image_id']}\\nTrue Label: {row['true_label']}\\nPredicted Label: {predicted_class}\")\n        plt.axis('off')\n        plt.show()\n        \nif CONFIG[\"sandbox\"]:       \n    predict_and_visualize_images_with_labels(selected_rows, model)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.443687Z","iopub.execute_input":"2023-10-27T10:13:54.443965Z","iopub.status.idle":"2023-10-27T10:13:54.457602Z","shell.execute_reply.started":"2023-10-27T10:13:54.443942Z","shell.execute_reply":"2023-10-27T10:13:54.456787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing on the test data","metadata":{}},{"cell_type":"code","source":"test_dataset = UBCDataset(df, transforms=data_transforms[\"valid\"])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'], \n                          num_workers=CONFIG[\"num_workers\"], shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.458730Z","iopub.execute_input":"2023-10-27T10:13:54.459036Z","iopub.status.idle":"2023-10-27T10:13:54.469981Z","shell.execute_reply.started":"2023-10-27T10:13:54.459007Z","shell.execute_reply":"2023-10-27T10:13:54.469112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = [\"HGSC\",\"EC\",\"CC\",\"LGSC\",\"MC\"]\n\n# Function to load the model and predict on selected image\ndef predict_on_image(model, image_path, device=CONFIG[\"device\"]):\n    print(device)\n    # Load the image and turn it into torch.float32 (same type as model)\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # Preprocess the image to get it between 0 and 1\n    transform = data_transforms[\"valid\"]\n    \n    image = transform(image=img)[\"image\"] # make sure image has batch dimension (shape: [batch_size, height, width, color_channels])\n    image = torch.tensor(np.expand_dims(image, axis=0))\n    print(image.to(device).dtype)\n    \n    # Predict on image\n    model.eval()\n    with torch.inference_mode():\n        # Put image to target device\n        image = image.to(device)\n        print(image.device)\n        \n        # Get prediction logits\n        pred_logits = model(image)\n        print(pred_logits)\n        # Get prediction probabilities\n        pred_probs = torch.softmax(pred_logits, dim=1)\n\n        # Get prediction label\n        pred_label = torch.argmax(pred_probs, dim=1).detach().cpu()\n        pred_label_class = class_names[pred_label]\n\n    print(f\"[INFO] Pred label: {pred_label} Pred class: {pred_label_class}, Pred prob: {pred_probs.max():.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.470981Z","iopub.execute_input":"2023-10-27T10:13:54.471293Z","iopub.status.idle":"2023-10-27T10:13:54.485258Z","shell.execute_reply.started":"2023-10-27T10:13:54.471270Z","shell.execute_reply":"2023-10-27T10:13:54.484326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names[int(traindf['label'][traindf['image_id']==10077])]","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.486352Z","iopub.execute_input":"2023-10-27T10:13:54.486875Z","iopub.status.idle":"2023-10-27T10:13:54.498007Z","shell.execute_reply.started":"2023-10-27T10:13:54.486850Z","shell.execute_reply":"2023-10-27T10:13:54.497142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG[\"train\"]:\n    predict_on_image(model, \"/kaggle/input/UBC-OCEAN/train_thumbnails/10077_thumbnail.png\", device=CONFIG[\"device\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.499185Z","iopub.execute_input":"2023-10-27T10:13:54.499524Z","iopub.status.idle":"2023-10-27T10:13:54.507492Z","shell.execute_reply.started":"2023-10-27T10:13:54.499492Z","shell.execute_reply":"2023-10-27T10:13:54.506615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create submission","metadata":{}},{"cell_type":"code","source":"preds = []\nwith torch.no_grad():\n    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n    for step, (data, _) in bar:        \n        images = data.to(CONFIG[\"device\"], dtype=torch.float)        \n        batch_size = images.size(0)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        \n        preds.append( predicted.detach().cpu().numpy() )\npreds = np.concatenate(preds).flatten()\npreds\n","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.508631Z","iopub.execute_input":"2023-10-27T10:13:54.509309Z","iopub.status.idle":"2023-10-27T10:13:54.954477Z","shell.execute_reply.started":"2023-10-27T10:13:54.509277Z","shell.execute_reply":"2023-10-27T10:13:54.953385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub_2 = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf_sub_2","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.955977Z","iopub.execute_input":"2023-10-27T10:13:54.956307Z","iopub.status.idle":"2023-10-27T10:13:54.969559Z","shell.execute_reply.started":"2023-10-27T10:13:54.956281Z","shell.execute_reply":"2023-10-27T10:13:54.968652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub_2 = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf_sub_2[\"label\"] = preds\n\ndef get_label(label):\n    return class_names[label]\n    \ndf_sub_2[\"label\"] = df_sub_2[\"label\"].apply(get_label)\ndf_sub_2 = df_sub_2.drop(\"image_width\", axis=1)\ndf_sub_2 = df_sub_2.drop(\"image_height\", axis=1)\ndf_sub_2.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.970794Z","iopub.execute_input":"2023-10-27T10:13:54.971101Z","iopub.status.idle":"2023-10-27T10:13:54.982434Z","shell.execute_reply.started":"2023-10-27T10:13:54.971077Z","shell.execute_reply":"2023-10-27T10:13:54.981564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check that submission looks reasonable","metadata":{}},{"cell_type":"code","source":"df_sub_2","metadata":{"execution":{"iopub.status.busy":"2023-10-27T10:13:54.983834Z","iopub.execute_input":"2023-10-27T10:13:54.984219Z","iopub.status.idle":"2023-10-27T10:13:54.996845Z","shell.execute_reply.started":"2023-10-27T10:13:54.984187Z","shell.execute_reply":"2023-10-27T10:13:54.995955Z"},"trusted":true},"execution_count":null,"outputs":[]}]}