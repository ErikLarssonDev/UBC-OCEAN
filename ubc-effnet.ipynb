{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":6799596,"sourceType":"datasetVersion","datasetId":3908722},{"sourceId":6957315,"sourceType":"datasetVersion","datasetId":3912057}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Environment setup","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom typing import Dict, List\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import balanced_accuracy_score\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom pathlib import Path\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(pow(2,60))\nprint(f\"torch version {torch.__version__}\") \nprint(f'Torchvision version {torchvision.__version__}')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:07.142173Z","iopub.execute_input":"2023-11-15T07:39:07.142683Z","iopub.status.idle":"2023-11-15T07:39:18.415691Z","shell.execute_reply.started":"2023-11-15T07:39:07.142641Z","shell.execute_reply":"2023-11-15T07:39:18.414003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    \"seed\": 42,\n    \"img_size\": 600,\n    \"model_name\": \"tf-efficientnet-b7\",\n    \"num_classes\": 5, # TODO: Handle that the 6th class is 'Other' in the test dataset\n    \"valid_batch_size\": 64,\n    \"test_batch_size\": 1,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    \"train\": False, # To train and save the model. Should be False when submitting\n    \"split_ratio\": 0.2,\n    \"num_workers\": os.cpu_count(),\n    \"epochs\": 30,\n    \"sandbox\": True, # True when finding optimal hyperparameters. Should be False when submitting.\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.418522Z","iopub.execute_input":"2023-11-15T07:39:18.419225Z","iopub.status.idle":"2023-11-15T07:39:18.426968Z","shell.execute_reply.started":"2023-11-15T07:39:18.419186Z","shell.execute_reply":"2023-11-15T07:39:18.425480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \n# set_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.429000Z","iopub.execute_input":"2023-11-15T07:39:18.429698Z","iopub.status.idle":"2023-11-15T07:39:18.441265Z","shell.execute_reply.started":"2023-11-15T07:39:18.429659Z","shell.execute_reply":"2023-11-15T07:39:18.439733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input/UBC-OCEAN'\nTEST_DIR = '/kaggle/input/UBC-OCEAN/test_thumbnails'\nALT_TEST_DIR = '/kaggle/input/UBC-OCEAN/test_images'\nTRAIN_DIR = '/kaggle/input/UBC-OCEAN/train_thumbnails'\nALT_TRAIN_DIR = '/kaggle/input/UBC-OCEAN/train_images'","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.443090Z","iopub.execute_input":"2023-11-15T07:39:18.443557Z","iopub.status.idle":"2023-11-15T07:39:18.457180Z","shell.execute_reply.started":"2023-11-15T07:39:18.443519Z","shell.execute_reply":"2023-11-15T07:39:18.455952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data processing","metadata":{}},{"cell_type":"code","source":"def get_test_file_path(image_id):\n    if os.path.exists(f\"{TEST_DIR}/{image_id}_thumbnail.png\"):\n        return f\"{TEST_DIR}/{image_id}_thumbnail.png\"\n    else: \n        return f\"{ALT_TEST_DIR}/{image_id}.png\"","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.460683Z","iopub.execute_input":"2023-11-15T07:39:18.461906Z","iopub.status.idle":"2023-11-15T07:39:18.469270Z","shell.execute_reply.started":"2023-11-15T07:39:18.461865Z","shell.execute_reply":"2023-11-15T07:39:18.467805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf['file_path'] = df['image_id'].apply(get_test_file_path)\ndf['label'] = 0 # dummy\ndf","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.472024Z","iopub.execute_input":"2023-11-15T07:39:18.472600Z","iopub.status.idle":"2023-11-15T07:39:18.519845Z","shell.execute_reply.started":"2023-11-15T07:39:18.472552Z","shell.execute_reply":"2023-11-15T07:39:18.517977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trim(im):\n    \"\"\"\n    Converts the image to grayscale using cv2, then computes binary matrix\n    of the pixels that are above a certrain threshold, then takes out the first\n    row where a certain percentage of the pixels are above the threshold will\n    be the first clip point. Same idea for col, max row, max col.\n    \"\"\"\n\n    percentage = 0.002\n    upper_percentage = 0.97\n\n    img = (np.array(im))\n    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    row_sums = np.sum(img_gray, axis=1)\n    col_sums = np.sum(img_gray, axis=0)\n    rows = np.where(np.logical_or(row_sums < img.shape[1] * percentage,\n                                  row_sums > img.shape[1] * upper_percentage))[0]\n    cols = np.where(np.logical_or(col_sums < img.shape[0] * percentage,\n                                  col_sums > img.shape[0] * upper_percentage))[0]\n    im_crop = np.delete(img, rows, axis=0)\n    im_crop = np.delete(im_crop, cols, axis=1)\n    return im_crop*255","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.521747Z","iopub.execute_input":"2023-11-15T07:39:18.522485Z","iopub.status.idle":"2023-11-15T07:39:18.532642Z","shell.execute_reply.started":"2023-11-15T07:39:18.522443Z","shell.execute_reply":"2023-11-15T07:39:18.531336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UBCDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        print(df['label'].values)\n        self.labels = df['label'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = trim(plt.imread(img_path))\n        label = self.labels[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return torch.tensor(img), torch.tensor(label, dtype=torch.long)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.534318Z","iopub.execute_input":"2023-11-15T07:39:18.534720Z","iopub.status.idle":"2023-11-15T07:39:18.549882Z","shell.execute_reply.started":"2023-11-15T07:39:18.534687Z","shell.execute_reply":"2023-11-15T07:39:18.548870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.),\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        # A.RandomBrightnessContrast(p=0.75),\n        A.ShiftScaleRotate(p=0.75),\n        A.OneOf([\n        A.GaussNoise(var_limit=[10, 50]),\n        A.GaussianBlur(),\n        A.MotionBlur(),\n        ], p=0.4),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n        A.CoarseDropout(max_holes=1, max_width=int(512* 0.3), max_height=int(512* 0.3), mask_fill_value=0, p=0.5),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:56:37.933170Z","iopub.execute_input":"2023-11-15T07:56:37.933683Z","iopub.status.idle":"2023-11-15T07:56:37.947235Z","shell.execute_reply.started":"2023-11-15T07:56:37.933645Z","shell.execute_reply":"2023-11-15T07:56:37.945730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    if os.path.exists(f\"{TRAIN_DIR}/{image_id}_thumbnail.png\"):\n        return f\"{TRAIN_DIR}/{image_id}_thumbnail.png\"\n    else:\n        return f\"{ALT_TRAIN_DIR}/{image_id}.png\"","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.566103Z","iopub.execute_input":"2023-11-15T07:39:18.566679Z","iopub.status.idle":"2023-11-15T07:39:18.583399Z","shell.execute_reply.started":"2023-11-15T07:39:18.566649Z","shell.execute_reply":"2023-11-15T07:39:18.581715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the training data frame for training","metadata":{}},{"cell_type":"code","source":"traindf = pd.read_csv('/kaggle/input/UBC-OCEAN/train.csv')\n\ntraindf['label'][traindf['label']==\"HGSC\"] = 0\ntraindf['label'][traindf['label']==\"EC\"] = 1\ntraindf['label'][traindf['label']==\"CC\"] = 2\ntraindf['label'][traindf['label']==\"LGSC\"] = 3\ntraindf['label'][traindf['label']==\"MC\"] = 4\ntraindf['file_path'] = traindf['image_id'].apply(get_train_file_path)\ntraindf","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:18.586110Z","iopub.execute_input":"2023-11-15T07:39:18.586506Z","iopub.status.idle":"2023-11-15T07:39:19.262093Z","shell.execute_reply.started":"2023-11-15T07:39:18.586475Z","shell.execute_reply":"2023-11-15T07:39:19.260631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = UBCDataset(traindf, transforms=data_transforms[\"train\"])\ntrain_dataloader = DataLoader(train_dataset, batch_size=CONFIG['valid_batch_size'], \n                          num_workers=CONFIG[\"num_workers\"], shuffle=True, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.263939Z","iopub.execute_input":"2023-11-15T07:39:19.264279Z","iopub.status.idle":"2023-11-15T07:39:19.273300Z","shell.execute_reply.started":"2023-11-15T07:39:19.264251Z","shell.execute_reply":"2023-11-15T07:39:19.272444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and validation split from the training set","metadata":{}},{"cell_type":"code","source":"# Split the data into training and validation sets\nif CONFIG[\"sandbox\"]:\n    train_data, val_data = train_test_split(traindf, test_size=CONFIG[\"split_ratio\"], random_state=CONFIG[\"seed\"])\n\n    train_dataset = UBCDataset(train_data, transforms=data_transforms[\"train\"])\n    train_dataloader = DataLoader(train_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=CONFIG[\"num_workers\"], shuffle=True, pin_memory=True)\n\n    val_dataset = UBCDataset(val_data, transforms=data_transforms[\"valid\"]) \n    val_dataloader = DataLoader(val_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=CONFIG[\"num_workers\"], shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.274690Z","iopub.execute_input":"2023-11-15T07:39:19.275579Z","iopub.status.idle":"2023-11-15T07:39:19.291637Z","shell.execute_reply.started":"2023-11-15T07:39:19.275542Z","shell.execute_reply":"2023-11-15T07:39:19.290397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"# Load train data\ntraindf.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.297612Z","iopub.execute_input":"2023-11-15T07:39:19.298015Z","iopub.status.idle":"2023-11-15T07:39:19.315556Z","shell.execute_reply.started":"2023-11-15T07:39:19.297984Z","shell.execute_reply":"2023-11-15T07:39:19.314374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.317337Z","iopub.execute_input":"2023-11-15T07:39:19.317849Z","iopub.status.idle":"2023-11-15T07:39:19.337969Z","shell.execute_reply.started":"2023-11-15T07:39:19.317807Z","shell.execute_reply":"2023-11-15T07:39:19.336492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf.isna().sum().sum() # No null values present","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.339752Z","iopub.execute_input":"2023-11-15T07:39:19.340145Z","iopub.status.idle":"2023-11-15T07:39:19.355383Z","shell.execute_reply.started":"2023-11-15T07:39:19.340103Z","shell.execute_reply":"2023-11-15T07:39:19.353621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf[['image_height', 'image_width']].describe()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.358253Z","iopub.execute_input":"2023-11-15T07:39:19.358762Z","iopub.status.idle":"2023-11-15T07:39:19.383994Z","shell.execute_reply.started":"2023-11-15T07:39:19.358725Z","shell.execute_reply":"2023-11-15T07:39:19.382563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HGSC = traindf[traindf['label']==0]\nEC = traindf[traindf['label']==1]\nCC = traindf[traindf['label']==2]\nLGSC = traindf[traindf['label']==3]\nMC = traindf[traindf['label']==4]","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.385810Z","iopub.execute_input":"2023-11-15T07:39:19.386205Z","iopub.status.idle":"2023-11-15T07:39:19.398388Z","shell.execute_reply.started":"2023-11-15T07:39:19.386172Z","shell.execute_reply":"2023-11-15T07:39:19.397189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the figure size\nplt.figure(figsize=(20, 6))\n\n# Set the font size\nplt.rcParams['font.size'] = 14\n\n# Set the colors\ncolors = ['lightgreen', 'lightblue', 'purple', 'blue', 'yellow']\n\n# Plot the pie chart for the training set\nplt.subplot(1, 1, 1)\nplt.pie([len(HGSC), len(EC), len(CC), len(LGSC), len(MC)], labels=['HGSC', 'EC', 'CC', 'LGSC', 'MC'], autopct='%1.1f%%', colors=colors)\nplt.title('Training Set')\n\n\n# Add a main title to the figure\nplt.suptitle('Distribution of HGSC, EC, CC, LGSC and MC Images in the Training data', fontsize=20, y=1.05)\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.400592Z","iopub.execute_input":"2023-11-15T07:39:19.401790Z","iopub.status.idle":"2023-11-15T07:39:19.698048Z","shell.execute_reply.started":"2023-11-15T07:39:19.401740Z","shell.execute_reply":"2023-11-15T07:39:19.696911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_transformed_image(dataframe, transform):\n    # Select a random row from the DataFrame\n    random_row = dataframe.sample(n=1).iloc[0]\n\n    # Get the image file path from the selected row\n    file_path = random_row['file_path']\n    print(random_row['is_tma'])\n    print(file_path)\n    # Load the original image\n    original_image = plt.imread(file_path)\n    trimmed_image = trim(original_image)\n    \n    # Apply the transform to the original image\n    transformed_image = transform(image=trimmed_image)[\"image\"]\n\n    # Visualize the original and transformed images\n    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n\n    axes[0].set_title('Original Image')\n    axes[0].imshow(original_image)\n    axes[0].axis('off')\n\n    axes[1].set_title('Transformed Image')\n    axes[1].imshow(transformed_image.permute(1, 2, 0))\n    axes[1].axis('off')\n\n    plt.show()\n\n# Visualize a random image from the DataFrame with the transform applied\nif CONFIG[\"sandbox\"]:\n    visualize_transformed_image(traindf, data_transforms[\"train\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:12.152150Z","iopub.execute_input":"2023-11-15T07:40:12.152671Z","iopub.status.idle":"2023-11-15T07:40:14.507769Z","shell.execute_reply.started":"2023-11-15T07:40:12.152632Z","shell.execute_reply":"2023-11-15T07:40:14.506743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and save model","metadata":{}},{"cell_type":"markdown","source":"## Save model","metadata":{}},{"cell_type":"code","source":"def save_model(model: torch.nn.Module,\n               target_dir: str,\n               model_name: str):\n    \"\"\"Saves a PyTorch model to a target directory.\n    \n    Args:\n        model: A target PyTorch model to save.\n        target_dir: A directory for saving the model to.\n        model_name: A filename for the saved model. Should include either \".pth\" or \".pt\" as the file extension.\n        \n    Example usage:\n        save_model(model=model_0,\n        targer_dir=\"models\", \n        model_name=\"model_1\")\n    \"\"\"\n\n    # Create target directory\n    target_dir_path = Path(target_dir)\n    target_dir_path.mkdir(parents=True,\n                          exist_ok=True)\n\n    # Create model save path\n    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"),  \"model_name should end with '.pt' or '.pth'\"\n    model_save_path = target_dir_path / model_name\n\n    # Save the model state_dict()\n    print(f\"[INFO] Saving model to : {model_save_path}\")\n    torch.save(obj=model,\n               f=model_save_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.700088Z","iopub.execute_input":"2023-11-15T07:39:19.700971Z","iopub.status.idle":"2023-11-15T07:39:19.709921Z","shell.execute_reply.started":"2023-11-15T07:39:19.700932Z","shell.execute_reply":"2023-11-15T07:39:19.708186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing a pretrained ViT\nThis is done online before we turn off the internet access. ","metadata":{}},{"cell_type":"code","source":"if CONFIG[\"train\"] or CONFIG[\"sandbox\"]:\n    # 1. Get pretrained weights for ViT-base\n    # pretrained_vit_weights = torchvision.models.ViT_H_14_Weights.DEFAULT\n    # pretrained_vit_weights=torch.load('/kaggle/input/vit-weights/vit_b_16-c867db91.pth')\n    pretrained_weights = torchvision.models.EfficientNet_B7_Weights.DEFAULT\n    # 2. Setup a ViT model instance with pretrained weights\n    # pretrained_vit = torchvision.models.vit_h_14(weights=pretrained_vit_weights).to(CONFIG[\"device\"])\n    pretrained_model = torchvision.models.efficientnet_b7(weights=pretrained_weights).to(CONFIG[\"device\"])\n    \n    # 3. Freeze the base parameters\n    for parameter in pretrained_model.parameters():\n        parameter.requires_grad = False\n        parameter.to(CONFIG[\"device\"])\n\n    # 4. Change the classifier head\n    set_seed()\n    pretrained_model.classifier = nn.Sequential(\n        nn.Linear(in_features=2560, out_features=1280),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(in_features=1280, out_features=640),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(in_features=640, out_features=320),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(in_features=320, out_features=CONFIG[\"num_classes\"]),\n    ).to(CONFIG[\"device\"])\n\n    \n    save_model(pretrained_model, # Needs to be saved as a dataset so that it works offline\n             \"/kaggle/working/\",\n             f\"{CONFIG['model_name']}.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:19.711856Z","iopub.execute_input":"2023-11-15T07:39:19.712608Z","iopub.status.idle":"2023-11-15T07:39:24.646127Z","shell.execute_reply.started":"2023-11-15T07:39:19.712560Z","shell.execute_reply":"2023-11-15T07:39:24.644305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"\"\"\"\nContains functions for training and testing a PyTorch model.\n\"\"\"\nimport torch\n\nfrom tqdm.auto import tqdm\nfrom typing import Dict, List, Tuple\n\ndef train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device) -> Tuple[float, float]:\n    \"\"\"Trains a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to training mode and then\n    runs through all of the required training steps (forward\n    pass, loss calculation, optimizer step).\n\n    Args:\n    model: A PyTorch model to be trained.\n    dataloader: A DataLoader instance for the model to be trained on.\n    loss_fn: A PyTorch loss function to minimize.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of training loss and training accuracy metrics.\n    In the form (train_loss, train_accuracy). For example:\n\n    (0.1112, 0.8743)\n    \"\"\"\n    # Put model in train mode\n    model.train()\n\n    # Setup train loss and train accuracy values\n    train_loss, train_acc = 0, 0\n\n    # Loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. Calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item() \n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n        # Calculate and accumulate accuracy metric across all batches\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n\n    # Adjust metrics to get average loss and accuracy per batch \n    train_loss = train_loss / len(dataloader)\n    train_acc = train_acc / len(dataloader)\n    return train_loss, train_acc\n\ndef test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader, \n              loss_fn: torch.nn.Module,\n              device: torch.device) -> Tuple[float, float]:\n    \"\"\"Tests a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to \"eval\" mode and then performs\n    a forward pass on a testing dataset.\n\n    Args:\n    model: A PyTorch model to be tested.\n    dataloader: A DataLoader instance for the model to be tested on.\n    loss_fn: A PyTorch loss function to calculate loss on the test data.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of testing loss and testing accuracy metrics.\n    In the form (test_loss, test_accuracy). For example:\n\n    (0.0223, 0.8985)\n    \"\"\"\n    # Put model in eval mode\n    model.eval() \n\n    # Setup test loss and test accuracy values\n    test_loss, test_acc, balanced_acc = 0, 0, 0\n    pred_labels = []\n    true_labels = []\n    # Turn on inference context manager\n    with torch.inference_mode():\n        # Loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # Send data to target device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred_logits = model(X)\n\n            # 2. Calculate and accumulate loss\n            loss = loss_fn(test_pred_logits, y)\n            test_loss += loss.item()\n\n            # Calculate and accumulate accuracy\n            test_pred_labels = test_pred_logits.argmax(dim=1)\n            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n            pred_labels = pred_labels + test_pred_labels.cpu().tolist()\n            true_labels = true_labels + y.cpu().tolist()\n\n    # Adjust metrics to get average loss and accuracy per batch \n    test_loss = test_loss / len(dataloader)\n    test_acc = test_acc / len(dataloader)\n    balanced_acc = balanced_accuracy_score(true_labels, pred_labels)\n    return test_loss, test_acc, balanced_acc\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device) -> Dict[str, List]:\n    \"\"\"Trains and tests a PyTorch model.\n\n    Passes a target PyTorch models through train_step() and test_step()\n    functions for a number of epochs, training and testing the model\n    in the same epoch loop.\n\n    Calculates, prints and stores evaluation metrics throughout.\n\n    Args:\n    model: A PyTorch model to be trained and tested.\n    train_dataloader: A DataLoader instance for the model to be trained on.\n    test_dataloader: A DataLoader instance for the model to be tested on.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n    epochs: An integer indicating how many epochs to train for.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A dictionary of training and testing loss as well as training and\n    testing accuracy metrics. Each metric has a value in a list for \n    each epoch.\n    In the form: {train_loss: [...],\n                  train_acc: [...],\n                  test_loss: [...],\n                  test_acc: [...]} \n    For example if training for epochs=2: \n                 {train_loss: [2.0616, 1.0537],\n                  train_acc: [0.3945, 0.3945],\n                  test_loss: [1.2641, 1.5706],\n                  test_acc: [0.3400, 0.2973]} \n    \"\"\"\n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n                \"train_acc\": [],\n                \"test_loss\": [],\n                \"test_acc\": [],\n                \"balanced_acc\": [],\n                }\n\n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                          dataloader=train_dataloader,\n                                          loss_fn=loss_fn,\n                                          optimizer=optimizer,\n                                          device=device)\n        test_loss, test_acc, balanced_acc = test_step(model=model,\n          dataloader=test_dataloader,\n          loss_fn=loss_fn,\n          device=device)\n\n        # Print out what's happening\n        print(\n                f\"Epoch: {epoch+1} | \"\n                f\"train_loss: {train_loss:.4f} | \"\n                f\"train_acc: {train_acc:.4f} | \"\n                f\"test_loss: {test_loss:.4f} | \"\n                f\"test_acc: {test_acc:.4f} | \"\n                f\"balanced_acc: {balanced_acc:.4f}\"\n        )\n\n        # Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        results[\"balanced_acc\"].append(balanced_acc)\n\n    # Return the filled results at the end of the epochs\n    return results","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:24.649434Z","iopub.execute_input":"2023-11-15T07:39:24.650076Z","iopub.status.idle":"2023-11-15T07:39:24.682115Z","shell.execute_reply.started":"2023-11-15T07:39:24.650028Z","shell.execute_reply":"2023-11-15T07:39:24.680486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming traindf is a DataFrame with a 'label' column\nclass_counts = traindf['label'].value_counts()\n\ntotal_samples = len(traindf)\nclass_weights = torch.tensor(total_samples / class_counts, dtype=torch.float)\n\n# Normalize weights to sum to 1\nclass_weights = class_weights / class_weights.sum()\n\nprint(\"Class Weights:\", class_weights)\nclass_counts","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:24.684456Z","iopub.execute_input":"2023-11-15T07:39:24.685772Z","iopub.status.idle":"2023-11-15T07:39:24.761578Z","shell.execute_reply.started":"2023-11-15T07:39:24.685727Z","shell.execute_reply":"2023-11-15T07:39:24.760467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create optimizer and loss function\ndef train_model(train_dl, test_dl, model_name, save=True):\n    optimizer = torch.optim.Adam(params=pretrained_model.parameters(),\n                                 lr=1e-3)\n    # loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights.to(CONFIG[\"device\"]))\n    loss_fn = torch.nn.CrossEntropyLoss()\n    if test_dl is None:\n        test_dl = train_dl\n    # Train the classifier head of the pretrained ViT feature extractor model\n    set_seed()\n    results = train(model=pretrained_model,\n                   train_dataloader=train_dl,\n                   test_dataloader=test_dl,\n                   optimizer=optimizer,\n                   loss_fn=loss_fn,\n                   epochs=CONFIG[\"epochs\"],\n                   device=CONFIG[\"device\"])\n    if save:\n        save_model(pretrained_model, \"/kaggle/working/\",f\"{CONFIG['model_name']}.pth\")\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:24.763189Z","iopub.execute_input":"2023-11-15T07:39:24.763596Z","iopub.status.idle":"2023-11-15T07:39:24.773225Z","shell.execute_reply.started":"2023-11-15T07:39:24.763565Z","shell.execute_reply":"2023-11-15T07:39:24.771717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG[\"train\"]:\n    results = train_model(train_dl=train_dataloader, test_dl=None, model_name=f\"{CONFIG['model_name']}.pth\")\nelif CONFIG[\"sandbox\"]:\n    results = train_model(train_dl=train_dataloader, test_dl=val_dataloader, model_name=f\"{CONFIG['model_name']}.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:39:24.775291Z","iopub.execute_input":"2023-11-15T07:39:24.775779Z","iopub.status.idle":"2023-11-15T07:40:05.766853Z","shell.execute_reply.started":"2023-11-15T07:39:24.775734Z","shell.execute_reply":"2023-11-15T07:40:05.764929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_curves(results: Dict[str, List[float]]):\n    \"\"\"Plots training curves of a results dictionary.\n\n    Args:\n        results (dict): dictionary containing list of values, e.g.\n            {\"train_loss\": [...],\n             \"train_acc\": [...],\n             \"test_loss\": [...],\n             \"test_acc\": [...]}\n    \"\"\"\n\n    # Get the loss values of the results dictionary (training and test)\n    loss = results['train_loss']\n    test_loss = results['test_loss']\n\n    # Get the accuracy values of the results dictionary (training and test)\n    accuracy = results['train_acc']\n    test_accuracy = results['test_acc']\n\n    # Figure out how many epochs there were\n    epochs = range(len(results['train_loss']))\n\n    # Setup a plot\n    plt.figure(figsize=(15, 7))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss, label='train_loss')\n    plt.plot(epochs, test_loss, label='test_loss')\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, accuracy, label='train_accuracy')\n    plt.plot(epochs, test_accuracy, label='test_accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()\n    \n    # Plot accuracy\n    plt.subplot(1, 1, 1)\n    plt.plot(epochs, results[\"balanced_acc\"], label='balanced_acc')\n    plt.title('Balanced Accuracy for validation data')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.768226Z","iopub.status.idle":"2023-11-15T07:40:05.768717Z","shell.execute_reply.started":"2023-11-15T07:40:05.768493Z","shell.execute_reply":"2023-11-15T07:40:05.768514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss curves\nif CONFIG[\"train\"] or CONFIG[\"sandbox\"]:\n    plot_loss_curves(results) ","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.771139Z","iopub.status.idle":"2023-11-15T07:40:05.771611Z","shell.execute_reply.started":"2023-11-15T07:40:05.771367Z","shell.execute_reply":"2023-11-15T07:40:05.771387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing the model","metadata":{}},{"cell_type":"code","source":"if CONFIG[\"sandbox\"]:\n    ViT = torch.load(f\"/kaggle/working/{CONFIG['model_name']}.pth\")\nelse:\n    ViT = torch.load(f\"/kaggle/input/{CONFIG['model_name']}.pth-trained/{CONFIG['model_name']}.pth\") # Needs to be loaded from the input folder so that it works offline","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.772903Z","iopub.status.idle":"2023-11-15T07:40:05.773314Z","shell.execute_reply.started":"2023-11-15T07:40:05.773122Z","shell.execute_reply":"2023-11-15T07:40:05.773142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = UBCDataset(df, transforms=data_transforms[\"valid\"])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'], \n                          num_workers=CONFIG[\"num_workers\"], shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.775211Z","iopub.status.idle":"2023-11-15T07:40:05.775666Z","shell.execute_reply.started":"2023-11-15T07:40:05.775458Z","shell.execute_reply":"2023-11-15T07:40:05.775479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = [\"HGSC\",\"EC\",\"CC\",\"LGSC\",\"MC\"]\n\n# Function to load the model and predict on selected image\ndef predict_on_image(model, image_path, device=CONFIG[\"device\"]):\n    # print(device)\n    # Load the image and turn it into torch.float32 (same type as model)\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # Preprocess the image to get it between 0 and 1\n    transform = data_transforms[\"valid\"]\n    \n    image = transform(image=img)[\"image\"] # make sure image has batch dimension (shape: [batch_size, height, width, color_channels])\n    image = torch.tensor(np.expand_dims(image, axis=0))\n    print(image.to(device).dtype)\n    \n    # Predict on image\n    model.eval()\n    with torch.inference_mode():\n        # Put image to target device\n        image = image.to(device)\n        print(image.device)\n        \n        # Get prediction logits\n        pred_logits = model(image)\n        print(pred_logits)\n        # Get prediction probabilities\n        pred_probs = torch.softmax(pred_logits, dim=1)\n\n        # Get prediction label\n        pred_label = torch.argmax(pred_probs, dim=1).detach().cpu()\n        pred_label_class = class_names[pred_label]\n\n    # print(f\"[INFO] Pred label: {pred_label} Pred class: {pred_label_class}, Pred prob: {pred_probs.max():.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.777170Z","iopub.status.idle":"2023-11-15T07:40:05.777918Z","shell.execute_reply.started":"2023-11-15T07:40:05.777700Z","shell.execute_reply":"2023-11-15T07:40:05.777720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names[int(traindf['label'][traindf['image_id']==10077])]","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.779734Z","iopub.status.idle":"2023-11-15T07:40:05.780150Z","shell.execute_reply.started":"2023-11-15T07:40:05.779949Z","shell.execute_reply":"2023-11-15T07:40:05.779968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG[\"train\"]:\n    predict_on_image(ViT, \"/kaggle/input/UBC-OCEAN/train_thumbnails/10077_thumbnail.png\", device=CONFIG[\"device\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.781314Z","iopub.status.idle":"2023-11-15T07:40:05.781773Z","shell.execute_reply.started":"2023-11-15T07:40:05.781551Z","shell.execute_reply":"2023-11-15T07:40:05.781570Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create submission","metadata":{}},{"cell_type":"code","source":"preds = []\nwith torch.no_grad():\n    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n    for step, (data, _) in bar:        \n        images = data.to(CONFIG[\"device\"], dtype=torch.float)        \n        batch_size = images.size(0)\n        outputs = ViT(images)\n        _, predicted = torch.max(outputs, 1)\n        \n        preds.append( predicted.detach().cpu().numpy() )\npreds = np.concatenate(preds).flatten()\npreds\n","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.783610Z","iopub.status.idle":"2023-11-15T07:40:05.784031Z","shell.execute_reply.started":"2023-11-15T07:40:05.783817Z","shell.execute_reply":"2023-11-15T07:40:05.783836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub_2 = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf_sub_2","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.785699Z","iopub.status.idle":"2023-11-15T07:40:05.786120Z","shell.execute_reply.started":"2023-11-15T07:40:05.785904Z","shell.execute_reply":"2023-11-15T07:40:05.785928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub_2 = pd.read_csv(f\"{ROOT_DIR}/test.csv\")\ndf_sub_2[\"label\"] = preds\n\ndef get_label(label):\n    return class_names[label]\n    \ndf_sub_2[\"label\"] = df_sub_2[\"label\"].apply(get_label)\ndf_sub_2 = df_sub_2.drop(\"image_width\", axis=1)\ndf_sub_2 = df_sub_2.drop(\"image_height\", axis=1)\ndf_sub_2.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.787933Z","iopub.status.idle":"2023-11-15T07:40:05.788346Z","shell.execute_reply.started":"2023-11-15T07:40:05.788151Z","shell.execute_reply":"2023-11-15T07:40:05.788170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check that submission looks reasonable","metadata":{}},{"cell_type":"code","source":"df_sub_2","metadata":{"execution":{"iopub.status.busy":"2023-11-15T07:40:05.789851Z","iopub.status.idle":"2023-11-15T07:40:05.790274Z","shell.execute_reply.started":"2023-11-15T07:40:05.790072Z","shell.execute_reply":"2023-11-15T07:40:05.790090Z"},"trusted":true},"execution_count":null,"outputs":[]}]}