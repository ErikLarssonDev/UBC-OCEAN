{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":7072028,"sourceType":"datasetVersion","datasetId":4026275},{"sourceId":7072368,"sourceType":"datasetVersion","datasetId":4045203},{"sourceId":7076136,"sourceType":"datasetVersion","datasetId":3984980}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Environment setup","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom typing import Dict, List\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom random import sample\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import balanced_accuracy_score\n\n# For Image Models\nimport timm\nfrom PIL import Image\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom pathlib import Path\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(pow(2,60))\nprint(f\"torch version {torch.__version__}\") \nprint(f'Torchvision version {torchvision.__version__}')","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:04.341673Z","iopub.execute_input":"2023-12-09T07:54:04.342030Z","iopub.status.idle":"2023-12-09T07:54:09.570403Z","shell.execute_reply.started":"2023-12-09T07:54:04.341998Z","shell.execute_reply":"2023-12-09T07:54:09.569229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    \"seed\": 42,\n    \"img_size\": 1024,\n    \"num_tiles\": 4,\n    \"model_name\": \"effnet-th-tiles-25\",\n    \"num_classes\": 5,\n    \"valid_batch_size\": 16,\n    \"test_batch_size\": 1,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n    \"train\": False, # To train and save the model. Should be False when submitting\n    \"split_ratio\": 0.2,\n    \"num_workers\": os.cpu_count(),\n    \"epochs\": 50,\n    \"sandbox\": True, # True when finding optimal hyperparameters. Should be False when submitting.\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:09.572070Z","iopub.execute_input":"2023-12-09T07:54:09.573122Z","iopub.status.idle":"2023-12-09T07:54:09.613694Z","shell.execute_reply.started":"2023-12-09T07:54:09.573092Z","shell.execute_reply":"2023-12-09T07:54:09.612479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input/processed-ubc-thumbnails'\nTRAIN_DIR = '/kaggle/input/processed-ubc-thumbnails/train_thumbnails'","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:09.614967Z","iopub.execute_input":"2023-12-09T07:54:09.615304Z","iopub.status.idle":"2023-12-09T07:54:09.624594Z","shell.execute_reply.started":"2023-12-09T07:54:09.615275Z","shell.execute_reply":"2023-12-09T07:54:09.623709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data processing","metadata":{}},{"cell_type":"code","source":"class UBCDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df['label'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        folder_path = self.file_names[index]\n        tiles_file_paths = os.listdir(folder_path)\n        tiles = []\n        for tile_path in tiles_file_paths:\n            tile = plt.imread(tile_path)\n            if self.transforms:\n                tile = self.transforms(image=tile)[\"image\"]\n            tiles.append(tile)\n            \n        label = self.labels[index]\n        \n        return torch.tensor(tiles), torch.tensor(label, dtype=torch.long)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:09.626828Z","iopub.execute_input":"2023-12-09T07:54:09.627465Z","iopub.status.idle":"2023-12-09T07:54:09.638888Z","shell.execute_reply.started":"2023-12-09T07:54:09.627433Z","shell.execute_reply":"2023-12-09T07:54:09.637918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.),\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        # A.RandomBrightnessContrast(p=0.75),\n        A.ShiftScaleRotate(p=0.75),\n        A.OneOf([\n        A.GaussNoise(var_limit=[10, 50]),\n        A.GaussianBlur(),\n        A.MotionBlur(),\n        ], p=0.4),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n        A.CoarseDropout(max_holes=1, max_width=int(512* 0.3), max_height=int(512* 0.3), mask_fill_value=0, p=0.5),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n}","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:09.639995Z","iopub.execute_input":"2023-12-09T07:54:09.640539Z","iopub.status.idle":"2023-12-09T07:54:09.650223Z","shell.execute_reply.started":"2023-12-09T07:54:09.640514Z","shell.execute_reply":"2023-12-09T07:54:09.649265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf = pd.read_csv('/kaggle/input/UBC-OCEAN/train.csv')\ntraindf","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:09.651903Z","iopub.execute_input":"2023-12-09T07:54:09.652372Z","iopub.status.idle":"2023-12-09T07:54:09.696427Z","shell.execute_reply.started":"2023-12-09T07:54:09.652341Z","shell.execute_reply":"2023-12-09T07:54:09.695537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    if os.path.exists(f\"{TRAIN_DIR}/{image_id}\"):\n        return f\"{TRAIN_DIR}/{image_id}\"\n    else:\n        return f\"NO FILE\"","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:09.697635Z","iopub.execute_input":"2023-12-09T07:54:09.697925Z","iopub.status.idle":"2023-12-09T07:54:09.704444Z","shell.execute_reply.started":"2023-12-09T07:54:09.697901Z","shell.execute_reply":"2023-12-09T07:54:09.703522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"traindf['file_path'] = traindf['image_id'].apply(get_train_file_path)\ntraindf","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:09.705902Z","iopub.execute_input":"2023-12-09T07:54:09.706283Z","iopub.status.idle":"2023-12-09T07:54:10.208246Z","shell.execute_reply.started":"2023-12-09T07:54:09.706252Z","shell.execute_reply":"2023-12-09T07:54:10.207112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the training data frame for training","metadata":{}},{"cell_type":"code","source":"traindf['label'][traindf['label']==\"HGSC\"] = 0\ntraindf['label'][traindf['label']==\"EC\"] = 1\ntraindf['label'][traindf['label']==\"CC\"] = 2\ntraindf['label'][traindf['label']==\"LGSC\"] = 3\ntraindf['label'][traindf['label']==\"MC\"] = 4\ntraindf = traindf[traindf['file_path'] != 'NO FILE']\ntraindf","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:10.209646Z","iopub.execute_input":"2023-12-09T07:54:10.210046Z","iopub.status.idle":"2023-12-09T07:54:10.235590Z","shell.execute_reply.started":"2023-12-09T07:54:10.210010Z","shell.execute_reply":"2023-12-09T07:54:10.234518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = UBCDataset(traindf, transforms=data_transforms[\"valid\"]) # TODO: Add training transforms\ntrain_dataloader = DataLoader(train_dataset, batch_size=CONFIG['valid_batch_size'], \n                          num_workers=CONFIG[\"num_workers\"], shuffle=True, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:10.240346Z","iopub.execute_input":"2023-12-09T07:54:10.241080Z","iopub.status.idle":"2023-12-09T07:54:10.247530Z","shell.execute_reply.started":"2023-12-09T07:54:10.241045Z","shell.execute_reply":"2023-12-09T07:54:10.246532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and validation split from the training set","metadata":{}},{"cell_type":"code","source":"# Split the data into training and validation sets\nif CONFIG[\"sandbox\"]:\n    train_data, val_data = train_test_split(traindf, test_size=CONFIG[\"split_ratio\"], random_state=CONFIG[\"seed\"])\n\n    train_dataset = UBCDataset(train_data, transforms=data_transforms[\"train\"]) # TODO: Add training transforms\n    train_dataloader = DataLoader(train_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=CONFIG[\"num_workers\"], shuffle=True, pin_memory=True)\n\n    val_dataset = UBCDataset(val_data, transforms=data_transforms[\"valid\"]) \n    val_dataloader = DataLoader(val_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=CONFIG[\"num_workers\"], shuffle=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:10.248874Z","iopub.execute_input":"2023-12-09T07:54:10.249208Z","iopub.status.idle":"2023-12-09T07:54:10.259956Z","shell.execute_reply.started":"2023-12-09T07:54:10.249178Z","shell.execute_reply":"2023-12-09T07:54:10.259019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and save model","metadata":{}},{"cell_type":"markdown","source":"## Save model","metadata":{}},{"cell_type":"code","source":"def save_model(model: torch.nn.Module,\n               target_dir: str,\n               model_name: str):\n    \"\"\"Saves a PyTorch model to a target directory.\n    \n    Args:\n        model: A target PyTorch model to save.\n        target_dir: A directory for saving the model to.\n        model_name: A filename for the saved model. Should include either \".pth\" or \".pt\" as the file extension.\n        \n    Example usage:\n        save_model(model=model_0,\n        targer_dir=\"models\", \n        model_name=\"model_1\")\n    \"\"\"\n\n    # Create target directory\n    target_dir_path = Path(target_dir)\n    target_dir_path.mkdir(parents=True,\n                          exist_ok=True)\n\n    # Create model save path\n    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"),  \"model_name should end with '.pt' or '.pth'\"\n    model_save_path = target_dir_path / model_name\n\n    # Save the model state_dict()\n    print(f\"[INFO] Saving model to : {model_save_path}\")\n    torch.save(obj=model,\n               f=model_save_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:10.261190Z","iopub.execute_input":"2023-12-09T07:54:10.261521Z","iopub.status.idle":"2023-12-09T07:54:10.271093Z","shell.execute_reply.started":"2023-12-09T07:54:10.261491Z","shell.execute_reply":"2023-12-09T07:54:10.270163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing a pretrained model\nThis is done online before we turn off the internet access. ","metadata":{}},{"cell_type":"markdown","source":"#### Indentity module for removing last classifier layer","metadata":{}},{"cell_type":"code","source":"class Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n        \n    def forward(self, x):\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:10.273008Z","iopub.execute_input":"2023-12-09T07:54:10.273535Z","iopub.status.idle":"2023-12-09T07:54:10.285350Z","shell.execute_reply.started":"2023-12-09T07:54:10.273503Z","shell.execute_reply":"2023-12-09T07:54:10.284364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG[\"train\"] or CONFIG[\"sandbox\"]:\n    # 1. Get pretrained weights for ViT-base\n    pretrained_weights = torchvision.models.EfficientNet_B7_Weights.DEFAULT\n    #pretrained_vit_weights=torch.load('/kaggle/input/vit-weights/vit_b_16-c867db91.pth')\n    # 2. Setup a ViT model instance with pretrained weights\n    pretrained_model = torchvision.models.efficientnet_b7(weights=pretrained_weights).to(CONFIG[\"device\"])\n\n    # 3. Freeze the base parameters\n    for parameter in pretrained_model.parameters():\n        parameter.requires_grad = False\n        parameter.to(CONFIG[\"device\"])\n\n    # 4. Change the classifier head\n    # set_seed()\n    # print(pretrained_model)\n\n    pretrained_model.classifier = Identity()\n    pretrained_model\n\n    save_model(pretrained_model, # Needs to be saved as a dataset so that it works offline\n             \"/kaggle/working/\",\n             f\"{CONFIG['model_name']}-pretrained.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:10.286679Z","iopub.execute_input":"2023-12-09T07:54:10.287039Z","iopub.status.idle":"2023-12-09T07:54:21.362754Z","shell.execute_reply.started":"2023-12-09T07:54:10.287015Z","shell.execute_reply":"2023-12-09T07:54:21.361747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False), # Same convolution, input == output dim. No bias due to batchnorm\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass U_NET(nn.Module):\n    def __init__(self, in_channels=3, out_channels=3, features=[16, 32, 64, 128, 256]):\n        super(U_NET, self).__init__()\n        self.ups = nn.ModuleList()\n        self.downs = nn.ModuleList()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Down part of U-NET\n        for feature in features:\n            self.downs.append(DoubleConv(in_channels, feature))\n            in_channels = feature\n        \n        # Up part of U-NET\n        for feature in reversed(features):\n            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n            self.ups.append(DoubleConv(feature*2, feature))\n\n        self.bottleneck= DoubleConv(features[-1], features[-1]*2)\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n\n    def forward(self, x):\n        skip_connections = []\n        for down in self.downs:\n            x = down(x)\n            skip_connections.append(x)\n            x = self.pool(x)\n\n        x = self.bottleneck(x)\n        skip_connections = skip_connections[::-1] # Reversing the list\n\n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip_connection = skip_connections[idx//2]\n            if x.shape != skip_connection.shape: # If we do inputs which are not divisible by 16 we need this\n                x = TF.resize(x, size=skip_connection.shape[2:]) # Just taking out height and width, not batch size and channels\n            concat_skip = torch.cat((skip_connection, x), dim=1)\n            x = self.ups[idx+1](concat_skip)\n        \n        return self.final_conv(x)\nUNET = U_NET()\n\nUNET.load_state_dict(torch.load('/kaggle/input/ubc-u-et/UNET_dict_80e_split_1024_tiles.pth'))\n# UNET = UNET.to(CONFIG[\"device\"])\n# test_vector = torch.randn((4, 3, 1024, 1024)).to(CONFIG[\"device\"])\n# print(test_vector.shape)\n# test_vector = UNET(test_vector)\n# print(test_vector.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:23.888366Z","iopub.execute_input":"2023-12-09T07:54:23.889609Z","iopub.status.idle":"2023-12-09T07:54:24.308304Z","shell.execute_reply.started":"2023-12-09T07:54:23.889574Z","shell.execute_reply":"2023-12-09T07:54:24.307365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CUT_OFF_UNET(nn.Module):\n    def __init__(self, UNET):\n        super(CUT_OFF_UNET, self).__init__()\n        self.UNET = UNET\n        self.conv = nn.Conv2d(256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    \n    def forward(self, x):\n        for down in self.UNET.downs:\n            x = down(x)\n            x = self.UNET.pool(x)\n        x = self.conv(x)\n        x = x.reshape(3, 64, 64)\n        return x\n    \nencoder = CUT_OFF_UNET(UNET).to(CONFIG[\"device\"])\ntest_vector = torch.randn((4, 3, 1024, 1024)).to(CONFIG[\"device\"])\nprint(encoder)\nprint(test_vector.shape)\nencoder.eval()\ntest_vector = encoder(test_vector)\nprint(test_vector.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-09T08:19:38.783278Z","iopub.execute_input":"2023-12-09T08:19:38.783712Z","iopub.status.idle":"2023-12-09T08:19:38.956050Z","shell.execute_reply.started":"2023-12-09T08:19:38.783681Z","shell.execute_reply":"2023-12-09T08:19:38.955027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature extraction --> Dim reduction (Vilket backbone som helst)\n# ([4, 3, 1024, 1024]) --> ([4, 256, 32, 32])\n\n# Go back to three channels\n# ([4, 256, 32, 32]) --> ([4, 3, 32, 32])\n\n# Create feature cube\n# ([4, 3, 32, 32]) --> ([3, 128, 128])\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM,self).__init__()\n        self.p = nn.Parameter(torch.ones(1)*p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):\n        return F.avg_pool1d(x.clamp(min=eps).pow(p), x.size(-1)).pow(1./p) # Changed to 1d since we only want to pool over the tiles dimension\n        \n    def __repr__(self):\n        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.383421Z","iopub.status.idle":"2023-12-09T07:54:21.383934Z","shell.execute_reply.started":"2023-12-09T07:54:21.383692Z","shell.execute_reply":"2023-12-09T07:54:21.383715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pooling = GeM()\ntest_vector = torch.randn((16, 25, 2560))\nprint(test_vector.permute(0, 2, 1).shape)\nprint(pooling(test_vector.permute(0, 2, 1)).squeeze(dim=-1).shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.384995Z","iopub.status.idle":"2023-12-09T07:54:21.385455Z","shell.execute_reply.started":"2023-12-09T07:54:21.385213Z","shell.execute_reply":"2023-12-09T07:54:21.385233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vector = torch.randn((16, 25, 2560))\nprint(test_vector.shape)\ntest_vector = test_vector.mean(dim=(-2))\nprint(test_vector.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.386814Z","iopub.status.idle":"2023-12-09T07:54:21.387398Z","shell.execute_reply.started":"2023-12-09T07:54:21.387189Z","shell.execute_reply":"2023-12-09T07:54:21.387208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SSFE(nn.Module):\n    def __init__(self, feature_extractor, backbone, backbone_output_dim):\n        super().__init__()\n        self.feature_extractor = feature_extractor.to(CONFIG[\"device\"])\n        self.backbone = backbone.to(CONFIG[\"device\"])\n        self.head = nn.Sequential(\n            nn.Dropout(0.8),\n            nn.Linear(in_features=backbone_output_dim, out_features=1024),\n            nn.ReLU(),\n            nn.Dropout(0.8),\n            nn.Linear(in_features=1024, out_features=128),\n            nn.ReLU(),\n            nn.Dropout(0.8),\n            nn.Linear(in_features=128, out_features=CONFIG[\"num_classes\"]),\n        ).to(CONFIG[\"device\"])\n        \n        def forward(self, x):\n            batch_features = torch.tensor([]).to(CONFIG[\"device\"])\n            for image in x: # [tile1, tile2,...]\n                tiles = torch.stack(image, dim=0) # (tile_number, tile)\n                # features = self.feature_extractor(tiles)\n                \n                \n                    \n        ","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.389039Z","iopub.status.idle":"2023-12-09T07:54:21.389493Z","shell.execute_reply.started":"2023-12-09T07:54:21.389253Z","shell.execute_reply":"2023-12-09T07:54:21.389274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# model = SSFE()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.390966Z","iopub.status.idle":"2023-12-09T07:54:21.391440Z","shell.execute_reply.started":"2023-12-09T07:54:21.391188Z","shell.execute_reply":"2023-12-09T07:54:21.391210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class tilingModel(nn.Module):\n    def __init__(self, backbone, n_tiles, tile_size, backbone_output_dim):\n        super().__init__()\n        self.backbone, self.n_tiles, self.tile_size = backbone.to(CONFIG[\"device\"]), n_tiles, tile_size\n        self.GeM_pooling = GeM()\n        self.head = nn.Sequential(\n            nn.Dropout(0.8),\n            nn.Linear(in_features=backbone_output_dim, out_features=1024),\n            nn.ReLU(),\n            nn.Dropout(0.8),\n            nn.Linear(in_features=1024, out_features=128),\n            nn.ReLU(),\n            nn.Dropout(0.8),\n            nn.Linear(in_features=128, out_features=CONFIG[\"num_classes\"]),\n        ).to(CONFIG[\"device\"])\n        \n    def forward(self, x): # TODO: Make this work for one batch at a time\n        images = split_images_into_tiles(x, self.tile_size) # Split x into tiles Result: [Batch_size, n_tiles, channels, width, height]\n        batch_features = torch.tensor([]).to(CONFIG[\"device\"])\n        \n        for tile in range(self.n_tiles): # TODO: Skip completely black tiles? Or maybe trim tiles?\n            tile_batch = images[:, tile, :, :, :] # Desired shape of [batch_size, channels, width, height]\n            batch_features = torch.cat((batch_features, self.backbone(tile_batch).unsqueeze(1)), dim = 1)\n        # batch_features = batch_features.mean(dim=(-2)) # Average pooling\n        batch_features = self.GeM_pooling(batch_features.permute(0, 2, 1)).squeeze(dim=-1)\n        x = self.head(batch_features)\n        return(x)\n\nif CONFIG[\"train\"] or CONFIG[\"sandbox\"]:                                                                        \n    tilingmodel = tilingModel(pretrained_model, CONFIG[\"num_tiles\"], 600, 2560).to(CONFIG[\"device\"])\n\n    img = plt.imread(\"/kaggle/input/UBC-OCEAN/train_thumbnails/10077_thumbnail.png\")\n    img = data_transforms[\"valid\"](image=img)[\"image\"]\n\n    img2 = plt.imread(\"/kaggle/input/UBC-OCEAN/train_thumbnails/10143_thumbnail.png\")\n    img2 = data_transforms[\"valid\"](image=img2)[\"image\"]\n\n    img_batch = torch.stack((img, img2))\n    print(f\"img_batch: {img_batch.shape}\")\n    output = tilingmodel(img_batch)\n    print(f\"Shape of output: {output.shape}\")\n    print(output)","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.393133Z","iopub.status.idle":"2023-12-09T07:54:21.393469Z","shell.execute_reply.started":"2023-12-09T07:54:21.393286Z","shell.execute_reply":"2023-12-09T07:54:21.393300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"\"\"\"\nContains functions for training and testing a PyTorch model.\n\"\"\"\nimport torch\n\nfrom tqdm.auto import tqdm\nfrom typing import Dict, List, Tuple\n\ndef train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device) -> Tuple[float, float]:\n    \"\"\"Trains a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to training mode and then\n    runs through all of the required training steps (forward\n    pass, loss calculation, optimizer step).\n\n    Args:\n    model: A PyTorch model to be trained.\n    dataloader: A DataLoader instance for the model to be trained on.\n    loss_fn: A PyTorch loss function to minimize.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of training loss and training accuracy metrics.\n    In the form (train_loss, train_accuracy). For example:\n\n    (0.1112, 0.8743)\n    \"\"\"\n    # Put model in train mode\n    model.train()\n\n    # Setup train loss and train accuracy values\n    train_loss, train_acc = 0, 0\n\n    # Loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. Calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item() \n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n        # Calculate and accumulate accuracy metric across all batches\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n\n    # Adjust metrics to get average loss and accuracy per batch \n    train_loss = train_loss / len(dataloader)\n    train_acc = train_acc / len(dataloader)\n    return train_loss, train_acc\n\ndef test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader, \n              loss_fn: torch.nn.Module,\n              device: torch.device) -> Tuple[float, float]:\n    \"\"\"Tests a PyTorch model for a single epoch.\n\n    Turns a target PyTorch model to \"eval\" mode and then performs\n    a forward pass on a testing dataset.\n\n    Args:\n    model: A PyTorch model to be tested.\n    dataloader: A DataLoader instance for the model to be tested on.\n    loss_fn: A PyTorch loss function to calculate loss on the test data.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A tuple of testing loss and testing accuracy metrics.\n    In the form (test_loss, test_accuracy). For example:\n\n    (0.0223, 0.8985)\n    \"\"\"\n    # Put model in eval mode\n    model.eval() \n\n    # Setup test loss and test accuracy values\n    test_loss, test_acc, balanced_acc = 0, 0, 0\n    pred_labels = []\n    true_labels = []\n    # Turn on inference context manager\n    with torch.inference_mode():\n        # Loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # Send data to target device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred_logits = model(X)\n\n            # 2. Calculate and accumulate loss\n            loss = loss_fn(test_pred_logits, y)\n            test_loss += loss.item()\n\n            # Calculate and accumulate accuracy\n            test_pred_labels = test_pred_logits.argmax(dim=1)\n            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n            pred_labels = pred_labels + test_pred_labels.cpu().tolist()\n            true_labels = true_labels + y.cpu().tolist()\n\n    # Adjust metrics to get average loss and accuracy per batch \n    test_loss = test_loss / len(dataloader)\n    test_acc = test_acc / len(dataloader)\n    balanced_acc = balanced_accuracy_score(true_labels, pred_labels)\n    return test_loss, test_acc, balanced_acc\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device) -> Dict[str, List]:\n    \"\"\"Trains and tests a PyTorch model.\n\n    Passes a target PyTorch models through train_step() and test_step()\n    functions for a number of epochs, training and testing the model\n    in the same epoch loop.\n\n    Calculates, prints and stores evaluation metrics throughout.\n\n    Args:\n    model: A PyTorch model to be trained and tested.\n    train_dataloader: A DataLoader instance for the model to be trained on.\n    test_dataloader: A DataLoader instance for the model to be tested on.\n    optimizer: A PyTorch optimizer to help minimize the loss function.\n    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n    epochs: An integer indicating how many epochs to train for.\n    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n    A dictionary of training and testing loss as well as training and\n    testing accuracy metrics. Each metric has a value in a list for \n    each epoch.\n    In the form: {train_loss: [...],\n                  train_acc: [...],\n                  test_loss: [...],\n                  test_acc: [...]} \n    For example if training for epochs=2: \n                 {train_loss: [2.0616, 1.0537],\n                  train_acc: [0.3945, 0.3945],\n                  test_loss: [1.2641, 1.5706],\n                  test_acc: [0.3400, 0.2973]} \n    \"\"\"\n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n                \"train_acc\": [],\n                \"test_loss\": [],\n                \"test_acc\": [],\n                \"balanced_acc\": [],\n                }\n\n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                          dataloader=train_dataloader,\n                                          loss_fn=loss_fn,\n                                          optimizer=optimizer,\n                                          device=device)\n        test_loss, test_acc, balanced_acc = test_step(model=model,\n          dataloader=test_dataloader,\n          loss_fn=loss_fn,\n          device=device)\n\n        # Print out what's happening\n        print(\n                f\"Epoch: {epoch+1} | \"\n                f\"train_loss: {train_loss:.4f} | \"\n                f\"train_acc: {train_acc:.4f} | \"\n                f\"test_loss: {test_loss:.4f} | \"\n                f\"test_acc: {test_acc:.4f} | \"\n                f\"balanced_acc: {balanced_acc:.4f}\"\n        )\n\n        # Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        results[\"balanced_acc\"].append(balanced_acc)\n\n    # Return the filled results at the end of the epochs\n    return results","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.394810Z","iopub.status.idle":"2023-12-09T07:54:21.395140Z","shell.execute_reply.started":"2023-12-09T07:54:21.394980Z","shell.execute_reply":"2023-12-09T07:54:21.394996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create optimizer and loss function\ndef train_model(train_dl, test_dl, model_name, store_model=True):\n    tilingmodel = tilingModel(pretrained_model, 4, 600, 2560).to(CONFIG[\"device\"])\n    optimizer = torch.optim.Adam(params=tilingmodel.parameters(),\n                                 lr=1e-3)\n    loss_fn = torch.nn.CrossEntropyLoss()\n    \n    if test_dl is None:\n        test_dl = train_dl\n    # Train the classifier head of the pretrained ViT feature extractor model\n    # set_seed()\n    results = train(model=tilingmodel,\n                   train_dataloader=train_dl,\n                   test_dataloader=test_dl,\n                   optimizer=optimizer,\n                   loss_fn=loss_fn,\n                   epochs=CONFIG[\"epochs\"],\n                   device=CONFIG[\"device\"])\n    if store_model:\n        save_model(tilingmodel, # Needs to be saved as a dataset so that it works offline\n                 \"/kaggle/working/\",\n                 model_name)\n        \n    return results","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.396135Z","iopub.status.idle":"2023-12-09T07:54:21.396471Z","shell.execute_reply.started":"2023-12-09T07:54:21.396283Z","shell.execute_reply":"2023-12-09T07:54:21.396297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG[\"train\"]:\n    results = train_model(train_dl=train_dataloader, test_dl=train_dataloader, model_name=f\"{CONFIG['model_name']}.pth\")\nelif CONFIG[\"sandbox\"]:\n    results = train_model(train_dl=train_dataloader, test_dl=val_dataloader, model_name=f\"{CONFIG['model_name']}.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.397811Z","iopub.status.idle":"2023-12-09T07:54:21.398108Z","shell.execute_reply.started":"2023-12-09T07:54:21.397959Z","shell.execute_reply":"2023-12-09T07:54:21.397973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_curves(results: Dict[str, List[float]]):\n    \"\"\"Plots training curves of a results dictionary.\n\n    Args:\n        results (dict): dictionary containing list of values, e.g.\n            {\"train_loss\": [...],\n             \"train_acc\": [...],\n             \"test_loss\": [...],\n             \"test_acc\": [...]}\n    \"\"\"\n\n    # Get the loss values of the results dictionary (training and test)\n    loss = results['train_loss']\n    test_loss = results['test_loss']\n\n    # Get the accuracy values of the results dictionary (training and test)\n    accuracy = results['train_acc']\n    test_accuracy = results['test_acc']\n\n    # Figure out how many epochs there were\n    epochs = range(len(results['train_loss']))\n\n    # Setup a plot\n    plt.figure(figsize=(15, 7))\n\n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, loss, label='train_loss')\n    plt.plot(epochs, test_loss, label='test_loss')\n    plt.title('Loss')\n    plt.xlabel('Epochs')\n    plt.legend()\n\n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, accuracy, label='train_accuracy')\n    plt.plot(epochs, test_accuracy, label='test_accuracy')\n    plt.title('Accuracy')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()\n    \n    # Plot accuracy\n    plt.subplot(1, 1, 1)\n    plt.plot(epochs, results[\"balanced_acc\"], label='balanced_acc')\n    plt.title('Balanced Accuracy for validation data')\n    plt.xlabel('Epochs')\n    plt.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.399460Z","iopub.status.idle":"2023-12-09T07:54:21.399792Z","shell.execute_reply.started":"2023-12-09T07:54:21.399628Z","shell.execute_reply":"2023-12-09T07:54:21.399643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss curves\nif CONFIG[\"train\"] or CONFIG[\"sandbox\"]:\n    plot_loss_curves(results) ","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.401703Z","iopub.status.idle":"2023-12-09T07:54:21.402008Z","shell.execute_reply.started":"2023-12-09T07:54:21.401858Z","shell.execute_reply":"2023-12-09T07:54:21.401872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_label(label):\n    return class_names[label]","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.402996Z","iopub.status.idle":"2023-12-09T07:54:21.403362Z","shell.execute_reply.started":"2023-12-09T07:54:21.403170Z","shell.execute_reply":"2023-12-09T07:54:21.403187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\nif CONFIG[\"sandbox\"]:\n    preds = []\n    true = []\n    with torch.no_grad():\n        bar = tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n        for step, (data, y) in bar:        \n            images = data.to(CONFIG[\"device\"], dtype=torch.float)        \n            batch_size = images.size(0)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            true.append(y.detach().cpu().numpy())\n            preds.append(predicted.detach().cpu().numpy())\n    preds = [get_label(item) for item in np.concatenate(preds).flatten()]\n    true = [get_label(item) for item in np.concatenate(true).flatten()]\n\n    # Compute the confusion matrix\n    cm = confusion_matrix(true, preds)\n\n    # Create a ConfusionMatrixDisplay with display_labels parameter\n    cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n    cmd.plot(cmap=plt.cm.Blues)  # You can choose a different color map if needed\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-09T07:54:21.404862Z","iopub.status.idle":"2023-12-09T07:54:21.405166Z","shell.execute_reply.started":"2023-12-09T07:54:21.405015Z","shell.execute_reply":"2023-12-09T07:54:21.405029Z"},"trusted":true},"execution_count":null,"outputs":[]}]}